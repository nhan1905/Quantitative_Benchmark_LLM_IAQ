{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7xzfPZzfVEty"},"outputs":[],"source":["import torch\n","import os\n","import gc\n","import json\n","import subprocess\n","import pandas as pd\n","from torch import cuda\n","from openai import OpenAI\n","from IPython.display import Markdown, display\n","import re\n","from google.colab import files, drive\n","\n","drive.mount('/content/drive')\n","\n","# USER INPUT\n","user_output_folder=\"Paste your Google Drive folder for storing LLMs output here\"\n","\n","user_base_url=\"https://openrouter.ai/api/v1\"\n","user_api_key=\"Paste your OpenRouter API here\"\n","\n","user_model = \"Paste LLMs OpenRouter address here\"\n","user_filename_id = \"Name the model here\"\n","user_max_token = 16384\n","\n","print(\"Done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcY7NKKJtVn-"},"outputs":[],"source":["class LLMSolver:\n","  def __init__(self, ulr=None, api=None, model=None, filename_id=None, token=0, folder=None):\n","    # Initialize OpenAI client with environment variable\n","    self.client=OpenAI(\n","        base_url=ulr,\n","        api_key=api,\n","    )\n","    self.model = model\n","    self.filename_id = filename_id\n","    self.max_token = token\n","    self.output_folder = folder\n","\n","    # Setup Google Drive and output folder\n","    self.setup_drive()\n","\n","  def setup_drive(self):\n","    \"\"\"Mount Google Drive and create output folder\"\"\"\n","    try:\n","      drive.mount('/content/drive')\n","      output_folder = self.output_folder\n","      os.makedirs(output_folder, exist_ok=True)\n","      print(f\"Markdown files will be saved to: {output_folder}\")\n","    except Exception as e:\n","      print(f\"Error setting up drive: {e}\")\n","\n","  def load_data(self):\n","    \"\"\"Upload and load CSV file\"\"\"\n","    try:\n","      uploaded = files.upload()\n","      filename = list(uploaded.keys())[0]\n","      df = pd.read_csv(filename)\n","      display(df.head(20))\n","      return df\n","    except Exception as e:\n","      print(f\"Error loading data: {e}\")\n","      return None\n","\n","  def prompt_design(self, mode):\n","      \"\"\"Get the appropriate prompt template based on mode\"\"\"\n","      PROMPT_GSR = \"\"\"\n","      Structure your responses using proper Markdown formatting with the following sections:\n","      Section 1: Problem summary\n","        Briefly restate the problem in your own words.\n","      Section 2: Given data\n","        List all the provided data with units and symbols using bullet points.\n","      Section 3: Find\n","        Clearly state what needs to be calculated.\n","      Section 4: Detailed Solution\n","        Show all calculation steps clearly and logically.\n","        Number each sub-step (e.g., **Step 4.1**, **Step 4.2**, etc.).\n","        Explain each step thoroughly, including assumptions, unit conversions, and equations used.\n","      Section 5: Solution Review\n","        Present the result with appropriate units and LaTeX formatting.\n","      Section 6: Final Answer\n","\n","      **IMPORTANT FORMATTING REQUIREMENTS:**\n","        - Use proper Markdown syntax (##, -, **, etc.)\n","        - NEVER use square brackets [ ] and ( ) for math\n","        - Format all mathematical expressions, equations, and formulas using LaTeX:\n","          - Use $...$ for inline math.  E.g., $x = 5$\n","          - Use $$...$$ for display math. E.g., $$x = 5$$\n","        - Use **bold** for emphasis and step labels\n","        - Use bullet points (-) for lists except for math\n","        - Do NOT use HTML tags like <h2>, <p>, <ul>, <li>\n","        - Ensure proper spacing between sections\n","      \"\"\"\n","\n","      mode_prompts = {\n","          \"NSD\": \"You will be provided with a calculation problem. Please solve it using the instructions above.\",\n","          \"IAQ\": (\"You are an expert in Indoor Air Quality Engineering (IAQ). You will be provided with a calculation problem. \"\n","                 \"Please solve it using appropriate IAQ equations, formulas, specific values, and constants. \"\n","                 \"Then, format your answer according to the instructions provided above.\"),\n","          \"AST\": \"You are an expert in the Aerosol Science and Technology field. You will be provided with a calculation problem. Please solve it using the instructions above.\"\n","      }\n","\n","      return PROMPT_GSR + mode_prompts.get(mode, mode_prompts[mode])\n","\n","  def ask_model(self, prompt, mode=None):\n","      \"\"\"Generate response from the AI model\"\"\"\n","      try:\n","        full_prompt = self.prompt_design(mode) + prompt\n","\n","        completion = self.client.chat.completions.create(\n","          extra_headers={\n","              \"HTTP-Referer\": \"Nhan Dinh Ngo\",\n","              \"X-Title\": \"Benchmarking LLM IAQ\",\n","          },\n","          model=self.model,\n","          messages=[{\"role\": \"user\", \"content\": full_prompt}],\n","          max_tokens=self.max_token\n","        )\n","\n","        return completion.choices[0].message.content\n","\n","      except Exception as e:\n","        print(f\"Error in ask_model: {e}\")\n","        return None\n","\n","  def display_Markdown(self,response):\n","    display(Markdown(response))\n","\n","  def save_Markdown(self, response, filename):\n","          \"\"\"Save response as Markdown file\"\"\"\n","          try:\n","              markdown_path = os.path.join(self.output_folder, f\"{filename}.md\")\n","\n","              # Add evaluation section\n","              evaluation_text = \"\"\"\n","## YOUR EVALUATION\n","- [1] Fully understand\n","- [0.5] Partially understand\n","- [0] Not Fully understand\n","- [1] Correct Result + Correct Equation\n","- [0.75] Wrong Results + Correct Equation\n","- [0.5] Correct Result + Wrong Equation\n","- [0] Wrong Results + Wrong Equation\n","\"\"\"\n","\n","              full_response = response + evaluation_text\n","\n","              # Save the markdown file\n","              with open(markdown_path, 'w', encoding='utf-8') as f:\n","                f.write(full_response)\n","\n","              print(f\"Markdown file saved successfully: {markdown_path}\")\n","              return filename, self.output_folder\n","\n","          except Exception as e:\n","              print(f\"Error in save_markdown_to_html: {e}\")\n","              return None, None\n","\n","  def process_problems(self, df, batch_size, answer_mode, max_problems, display, save):\n","      \"\"\"Process problems from DataFrame\"\"\"\n","      try:\n","          for i_batch in range(1, batch_size + 1):\n","              for index, row in df.iloc[:max_problems].iterrows():\n","                  example_id = str(row[\"Example 2\"]).strip()\n","                  problem = str(row[\"Problems\"]).strip()\n","\n","                  batch_filename = f\"Name: {example_id}-{answer_mode}-{self.filename_id}-{i_batch}\"\n","                  print(f\"Generating response for {batch_filename}...\")\n","\n","                  # Generate response\n","                  response = self.ask_model(problem, answer_mode)\n","                  if not response:\n","                      print(f\"Failed to generate response for {batch_filename}\")\n","                      continue\n","\n","                  if display == True:\n","                    # Display result\n","                    self.display_Markdown(response)\n","\n","                  if save == True:\n","                    # Save to Markdown\n","                    save_filename, save_folder = self.save_Markdown(response, batch_filename)\n","                    if save_filename:\n","                        print(f\"Successfully saved file {save_filename} to folder {save_folder}\")\n","\n","          print(\"Done processing all problems\")\n","\n","      except Exception as e:\n","          print(f\"Error in process_problems: {e}\")\n","\n","# Initialize the solver\n","def initialize_solver():\n","    \"\"\"Initialize and return the LLMSolver instance\"\"\"\n","    solver = LLMSolver(\n","        user_base_url,\n","        user_api_key,\n","        user_model,\n","        user_filename_id,\n","        user_max_token,\n","        user_output_folder\n","    )\n","    return solver\n","\n","# Load CSV file\n","def load_data(solver):\n","    df = solver.load_data()\n","    total_rows = len(df)\n","    print(f\"Total rows in dataset: {total_rows}\")\n","    return df, total_rows\n","\n","# Run model\n","def run_model(solver, df, batchsize, answermode, maxproblems, displays, saves):\n","    solver.process_problems(df, batch_size=batchsize, answer_mode=answermode, max_problems=maxproblems, display=displays, save=saves)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KIRVPJBeTmYe"},"outputs":[],"source":["# Initialize the solver\n","solver = initialize_solver()\n","\n","# Load CSV data\n","df, total_problems = load_data(solver)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"L6b8VcYOm2y0"},"outputs":[],"source":["# Run the model\n","run_model(\n","    solver,\n","    df,\n","    batchsize=5,\n","    answermode = \"IAQ\",\n","    maxproblems = total_problems,\n","    displays = False,\n","    saves = True\n",")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"authorship_tag":"ABX9TyP0jXmEqGGsODK9mAj0u8RW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}